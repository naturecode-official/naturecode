import { Command } from "commander";
import { readFile } from "fs/promises";
import { spawn } from "child_process";
import { fileURLToPath } from "url";
import { dirname, join } from "path";
import { existsSync } from "fs";

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

export function createHelpCommand() {
  const helpCommand = new HelpCommand();
  return helpCommand.getCommand();
}

export class HelpCommand {
  constructor() {
    this.command = new Command("help")
      .description("Get direct AI assistance for NatureCode")
      .argument("[question]", "Your question about NatureCode")
      .option("-s, --simple", "Use simple help without AI")
      .option("-d, --docs", "Show full documentation")
      .option("-i, --install-ollama", "Install Ollama automatically")
      .action(this.handleCommand.bind(this));
  }

  getCommand() {
    return this.command;
  }

  async handleCommand(question, options) {
    try {
      if (options.docs) {
        await this.showFullDocs();
        return;
      }

      if (options.installOllama) {
        await this.installOllama();
        return;
      }

      if (options.simple) {
        await this.showSimpleHelp();
        return;
      }

      // Direct AI assistance - no intermediate steps
      if (!question) {
        // Start direct AI chat immediately
        await this.startDirectAIChat();
        return;
      }

      // Get immediate AI help for the question
      await this.getDirectAIHelp(question);
    } catch (error) {
      console.error("Error getting help:", error.message);
      console.log("\nFalling back to simple help...");
      await this.showSimpleHelp();
    }
  }

  async showSimpleHelp() {
    const helpText = `
NatureCode v1.4.5.5 - Cross-platform Terminal AI Assistant

Available Commands:
  start              Start interactive AI session
  model              Configure AI model and API
  help [question]    Get direct AI assistance

File System:
  read <file>        Read file content
  edit <file>        Edit file
  create <file>      Create new file
  delete <file>      Delete file
  list <dir>         List directory contents

Git Integration:
  git status         Show Git status
  git diff           Show changes
  git commit         Commit changes
  git push           Push to remote
  git pull           Pull from remote

Code Analysis:
  code analyze       Analyze code quality
  code review        Code review with AI
  code metrics       Show code metrics

Project Management:
  project analyze    Analyze project structure
  project create     Create new project
  project deps       Analyze dependencies

Configuration:
  config show        Show configuration
  config get <key>   Get config value
  config set <key> <value> Set config value

Plugins:
  plugin list        List installed plugins
  plugin info <id>   Show plugin information
  plugin install <source> Install plugin

Sessions:
  session list       List all sessions
  session create <name> Create new session
  session switch <id> Switch to session

Team Collaboration:
  team create <name> Create new team
  team join <code>   Join existing team
  team list          List all teams

Integration:
  integration status Show integration status
  integration analyze Analyze project for tools

Performance:
  performance start  Start performance monitoring
  performance status Show current metrics
  performance report Generate performance report

Options:
  --help             Show help
  --version          Show version
  --simple           Use simple help without AI
  --docs             Show full documentation
  --install-ollama   Install Ollama automatically

Examples:
  naturecode help                    # Start direct AI chat
  naturecode help "configure model"  # Get AI help for specific question
  naturecode help --simple           # Simple help without AI
  naturecode help --docs             # Full documentation
  naturecode help --install-ollama   # Install Ollama automatically

For direct AI assistance, just run: naturecode help
For specific questions: naturecode help "your question"
`;

    console.log(helpText);
  }

  async showFullDocs() {
    try {
      const docsPath = join(__dirname, "../../../docs.md");
      if (existsSync(docsPath)) {
        const docsContent = await readFile(docsPath, "utf-8");
        console.log(docsContent);
      } else {
        console.log("Documentation file not found. Generating summary...");
        await this.showSimpleHelp();
      }
    } catch (error) {
      console.error("Error reading documentation:", error.message);
      await this.showSimpleHelp();
    }
  }

  async startDirectAIChat() {
    console.clear();
    console.log("NatureCode AI Assistant v1.4.5.5\n");
    console.log("=".repeat(70));
    console.log("Direct AI Assistance Mode");
    console.log("=".repeat(70));
    console.log("I'm ready to help you with NatureCode!");
    console.log("Ask me anything about commands, configuration, or usage.");
    console.log("\nType 'exit' to end the conversation.");
    console.log("=".repeat(70) + "\n");

    // Check and setup Ollama if needed
    const setupSuccess = await this.setupOllamaForDirectChat();
    if (!setupSuccess) {
      return;
    }

    // Get documentation context
    const docsContext = await this.getDocsContext();

    // Start direct chat
    await this.startDirectChatLoop(docsContext);
  }

  async setupOllamaForDirectChat() {
    try {
      // Check if Ollama is installed
      const ollamaInstalled = await this.checkOllamaInstalled();
      if (!ollamaInstalled) {
        console.log("Setting up Ollama for AI assistance...");
        const installSuccess = await this.autoInstallOllama();
        if (!installSuccess) {
          console.log("\nCould not set up Ollama. Using simple help instead.");
          await this.showSimpleHelp();
          return false;
        }
      }

      // Check if DeepSeek model is available
      const deepseekAvailable = await this.checkDeepSeekModel();
      if (!deepseekAvailable) {
        console.log("Downloading AI model...");
        const pullSuccess = await this.autoPullDeepSeekModel();
        if (!pullSuccess) {
          console.log(
            "\nCould not download AI model. Using simple help instead.",
          );
          await this.showSimpleHelp();
          return false;
        }
      }

      return true;
    } catch (error) {
      console.error("Setup error:", error.message);
      return false;
    }
  }

  async getDirectAIHelp(question) {
    console.log("NatureCode AI Assistant v1.4.5.5\n");

    try {
      // Check if Ollama is available first
      const ollamaInstalled = await this.checkOllamaInstalled();
      if (!ollamaInstalled) {
        console.log("ğŸ¤– Setting up AI assistant for the first time...");
        console.log("This will install Ollama and download an AI model.");
        console.log(
          "It may take a few minutes depending on your internet speed.\n",
        );

        const setupSuccess = await this.setupOllamaForDirectChat();
        if (!setupSuccess) {
          console.log("\nğŸ“š Showing documentation-based help instead...");
          await this.showDocsBasedHelp(question);
          return;
        }
      }

      // Setup Ollama if needed
      const setupSuccess = await this.setupOllamaForDirectChat();
      if (!setupSuccess) {
        console.log("\nğŸ“š Showing documentation-based help instead...");
        await this.showDocsBasedHelp(question);
        return;
      }

      // Get documentation context
      const docsContext = await this.getDocsContext();

      // Prepare prompt
      const prompt = this.createDirectHelpPrompt(question, docsContext);

      console.log("Thinking...\n");

      try {
        const answer = await this.callOllama(prompt);

        console.log("\n" + "=".repeat(70));
        console.log("AI Assistance:");
        console.log("=".repeat(70));
        console.log(answer);
        console.log("=".repeat(70));
        console.log("\nNeed more help? Run: naturecode help");
      } catch (ollamaError) {
        console.log(
          "\nâš ï¸  AI assistant is taking longer than expected to respond.",
        );
        console.log("This could be because:");
        console.log("  1. The AI model is still loading (first time use)");
        console.log("  2. Your system needs more resources");
        console.log("  3. Network connectivity issues\n");

        console.log("ğŸ“š In the meantime, here's documentation-based help:");
        console.log("=".repeat(70));
        await this.showDocsBasedHelp(question);
      }
    } catch (error) {
      console.error("\nError:", error.message);
      console.log("\nğŸ“š Showing documentation-based help instead...");
      await this.showDocsBasedHelp(question);
    }
  }

  async startDirectChatLoop(docsContext) {
    const readline = await import("readline");
    const rl = readline.createInterface({
      input: process.stdin,
      output: process.stdout,
      prompt: "> ",
    });

    let conversationHistory = [];

    rl.prompt();

    rl.on("line", async (line) => {
      const userInput = line.trim();

      if (!userInput) {
        rl.prompt();
        return;
      }

      if (userInput.toLowerCase() === "exit") {
        console.log("\nGoodbye!");
        rl.close();
        return;
      }

      if (userInput.toLowerCase() === "clear") {
        console.clear();
        console.log("NatureCode AI Assistant v1.4.5.5\n");
        rl.prompt();
        return;
      }

      // Show thinking indicator
      process.stdout.write("Thinking... ");

      try {
        // Prepare prompt with conversation history
        const prompt = this.createDirectChatPrompt(
          userInput,
          docsContext,
          conversationHistory,
        );

        // Get AI response
        const response = await this.callOllama(prompt);

        // Clear thinking indicator
        process.stdout.write("\r" + " ".repeat(50) + "\r");

        // Add to conversation history
        conversationHistory.push({ role: "user", content: userInput });
        conversationHistory.push({ role: "assistant", content: response });

        // Show response
        console.log("\n" + response + "\n");
      } catch (error) {
        process.stdout.write("\r" + " ".repeat(50) + "\r");
        console.log("\nError: " + error.message);
        console.log("Please try again.\n");
      }

      rl.prompt();
    });

    rl.on("close", () => {
      console.log("\nAI assistance session ended.");
      process.exit(0);
    });
  }

  createDirectHelpPrompt(question, docsContext) {
    return `You are NatureCode AI Assistant, an expert guide for NatureCode v1.4.5.5.

You are providing direct AI assistance to a user who needs help with NatureCode.
Provide clear, practical, and actionable help.

Documentation context:
${docsContext}

User's question: ${question}

Provide a direct answer with:
1. Clear explanation
2. Step-by-step instructions if needed
3. Exact commands they can copy/paste
4. Format code examples with \`\`\`bash ... \`\`\`
5. Keep it concise but complete

Answer directly without introductions:`;
  }

  createDirectChatPrompt(question, docsContext, history) {
    // Limit history to last 3 exchanges
    const recentHistory = history.slice(-3);

    let historyText = "";
    for (const exchange of recentHistory) {
      if (exchange.role === "user") {
        historyText += `User: ${exchange.content}\n`;
      } else {
        historyText += `Assistant: ${exchange.content}\n`;
      }
    }

    return `You are NatureCode AI Assistant, an expert guide for NatureCode v1.4.5.5.

You are in a direct chat session helping a user with NatureCode.

Documentation context:
${docsContext}

Previous conversation:
${historyText}

Current question:
User: ${question}

Provide direct, practical help. Include commands they can run.
Answer concisely but completely.

Answer:`;
  }

  async getDocsContext() {
    try {
      const docsPath = join(__dirname, "../../../docs.md");
      if (existsSync(docsPath)) {
        const docsContent = await readFile(docsPath, "utf-8");

        // Extract relevant sections based on content length
        if (docsContent.length > 8000) {
          // For large docs, get introduction and table of contents
          const introMatch = docsContent.match(/(^.*?##.*?\n)/s);
          const tocMatch = docsContent.match(/(## Table of Contents.*?\n## )/s);

          let context = "";
          if (introMatch) context += introMatch[1];
          if (tocMatch) context += tocMatch[1];

          // Also get the last 2000 characters which might have recent updates
          context +=
            "\n\nRecent updates and details:\n" + docsContent.substring(-2000);

          return context.substring(0, 6000); // Limit to 6000 chars
        } else {
          // For smaller docs, return everything
          return docsContent;
        }
      } else {
        // Create minimal docs context if file doesn't exist
        return this.createMinimalDocsContext();
      }
    } catch (error) {
      console.error("Error reading documentation:", error.message);
      return this.createMinimalDocsContext();
    }
  }

  createMinimalDocsContext() {
    return `NatureCode v1.4.5.5 - Cross-platform Terminal AI Assistant

## Overview
NatureCode is an AI-powered terminal assistant that helps developers with coding tasks, file operations, and project management.

## Core Commands
- start: Start interactive AI session
- model: Configure AI model and API settings
- help: Get direct AI assistance
- config: Show current configuration
- delmodel: Delete model configuration

## AI Providers
1. DeepSeek: Cloud-based AI (requires API key)
2. OpenAI: Industry-leading models (requires API key)
3. Ollama: Local AI models (free, runs on your machine)

## File Operations
- Read, write, create, delete files
- List directory contents
- Search files by pattern

## Code Analysis
- Code quality analysis
- AI-powered code review
- Code metrics

## Project Management
- Project structure analysis
- Dependency analysis
- Task management

## Getting Started
1. Configure AI model: naturecode model
2. Start session: naturecode start
3. Get help: naturecode help "your question"

## Ollama Integration
NatureCode can use Ollama for local AI processing. When you run 'help' command, it will automatically install Ollama and download AI models if needed.`;
  }

  async checkOllamaInstalled() {
    return new Promise((resolve) => {
      const process = spawn("which", ["ollama"], { stdio: "ignore" });
      process.on("close", (code) => {
        resolve(code === 0);
      });
    });
  }

  async checkDeepSeekModel() {
    return new Promise((resolve) => {
      const process = spawn("ollama", ["list"], { stdio: "pipe" });
      let output = "";

      process.stdout.on("data", (data) => {
        output += data.toString();
      });

      process.on("close", (code) => {
        if (code === 0) {
          // Check for various DeepSeek models
          const hasDeepSeek =
            output.includes("deepseek-coder") ||
            output.includes("deepseek-chat") ||
            output.includes("deepseek-r1") ||
            output.includes("deepseek-v2") ||
            output.includes("deepseek-v2.5");
          resolve(hasDeepSeek);
        } else {
          resolve(false);
        }
      });

      process.on("error", () => {
        resolve(false);
      });
    });
  }

  async callOllama(prompt) {
    return new Promise((resolve, reject) => {
      // Try available models in order
      const modelsToTry = [
        "deepseek-coder",
        "deepseek-chat",
        "llama3.2",
        "llama3.1",
        "llama3",
        "mistral",
        "codellama",
      ];

      const tryModel = (index) => {
        if (index >= modelsToTry.length) {
          reject(
            new Error(
              "No available Ollama models found. Please install a model with: ollama pull deepseek-coder",
            ),
          );
          return;
        }

        const model = modelsToTry[index];
        const process = spawn("ollama", ["run", model], {
          stdio: "pipe",
          timeout: 30000, // 30 second timeout
        });

        let output = "";
        let errorOutput = "";
        let timeoutId = null;

        // Set timeout
        timeoutId = setTimeout(() => {
          if (process && !process.killed) {
            process.kill("SIGTERM");
          }
          // Try next model on timeout
          tryModel(index + 1);
        }, 30000);

        process.stdin.write(prompt);
        process.stdin.end();

        process.stdout.on("data", (data) => {
          output += data.toString();
        });

        process.stderr.on("data", (data) => {
          errorOutput += data.toString();
        });

        process.on("close", (code) => {
          if (timeoutId) clearTimeout(timeoutId);

          if (code === 0 && output.trim()) {
            resolve(output.trim());
          } else {
            // Log error for debugging
            if (errorOutput && errorOutput.includes("model")) {
              console.log(`Model "${model}" not found, trying next...`);
            }
            // Try next model
            tryModel(index + 1);
          }
        });

        process.on("error", (error) => {
          if (timeoutId) clearTimeout(timeoutId);
          // Try next model on error
          tryModel(index + 1);
        });
      };

      // Start with first model
      tryModel(0);
    });
  }

  async autoInstallOllama() {
    console.log("Setting up AI assistant...");

    const platform = process.platform;

    if (platform === "win32") {
      console.log("For Windows:");
      console.log("1. Download Ollama from https://ollama.ai/download");
      console.log("2. Install and run: ollama pull deepseek-coder");
      return false;
    }

    // macOS and Linux
    console.log("Installing Ollama...");

    const { exec } = await import("child_process");

    return new Promise((resolve) => {
      // Install Ollama
      exec(
        "curl -fsSL https://ollama.ai/install.sh | sh",
        (installError, _installStdout, _installStderr) => {
          if (installError) {
            console.log("Installation may need manual steps.");
            console.log("Please install from: https://ollama.ai");
            resolve(false);
            return;
          }

          console.log("Ollama installed. Downloading AI model...");

          // Try to download a model
          this.autoPullDeepSeekModel().then((success) => {
            if (success) {
              console.log("\nAI assistant setup complete!");
              console.log("You can now use: naturecode help");
              resolve(true);
            } else {
              resolve(false);
            }
          });
        },
      );
    });
  }

  async autoPullDeepSeekModel() {
    console.log("Downloading AI model...");

    const { exec } = await import("child_process");

    // Try different models in order of preference
    const modelsToTry = [
      "deepseek-coder:latest",
      "deepseek-coder:6.7b",
      "deepseek-chat:latest",
      "deepseek-chat:6.7b",
      "deepseek-r1:latest",
      "llama3.2:latest",
      "llama3.1:latest",
      "llama3:latest",
      "mistral:latest",
      "codellama:latest",
    ];

    return new Promise((resolve) => {
      const tryModel = (index) => {
        if (index >= modelsToTry.length) {
          console.log("\nCould not download any AI model.");
          console.log("Please install a model manually:");
          console.log("  ollama pull deepseek-coder");
          resolve(false);
          return;
        }

        const model = modelsToTry[index];
        console.log(`\nTrying ${model}...`);

        exec(`ollama pull ${model}`, (error, _stdout, _stderr) => {
          if (error) {
            console.log(`Failed to pull ${model}`);
            // Try next model
            tryModel(index + 1);
          } else {
            console.log(`Successfully downloaded ${model}!`);
            resolve(true);
          }
        });
      };

      // Start with first model
      tryModel(0);
    });
  }

  async installOllama() {
    console.log("Setting up AI assistant...");

    const platform = process.platform;

    if (platform === "win32") {
      console.log("For Windows:");
      console.log("1. Download Ollama from https://ollama.ai/download");
      console.log("2. Install and run: ollama pull deepseek-coder");
      return;
    }

    // macOS and Linux
    console.log("Installing Ollama...");

    const { exec } = await import("child_process");

    // Install Ollama
    exec(
      "curl -fsSL https://ollama.ai/install.sh | sh",
      (installError, _installStdout, _installStderr) => {
        if (installError) {
          console.log("Installation may need manual steps.");
          console.log("Please install from: https://ollama.ai");
          return;
        }

        console.log("Ollama installed. Downloading AI model...");

        // Try to download a model
        this.autoPullDeepSeekModel().then((success) => {
          if (success) {
            console.log("\nAI assistant setup complete!");
            console.log("You can now use: naturecode help");
          }
        });
      },
    );
  }

  async showDocsBasedHelp(question) {
    try {
      const docsContext = await this.getDocsContext();

      // Simple keyword matching for common questions
      const lowerQuestion = question.toLowerCase();

      console.log("\n" + "=".repeat(70));
      console.log("NatureCode AI åŠ©æ‰‹ - æ–‡æ¡£å¸®åŠ©");
      console.log("=".repeat(70));

      // Handle "who are you" questions in Chinese
      if (
        lowerQuestion.includes("ä½ æ˜¯è°") ||
        lowerQuestion.includes("who are you") ||
        lowerQuestion.includes("what are you")
      ) {
        console.log(`
 ğŸ¤– æˆ‘æ˜¯ NatureCode AI åŠ©æ‰‹ï¼

 æˆ‘æ˜¯ NatureCode v1.4.5.5 çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©å¼€å‘è€…ï¼š
 â€¢ ä½¿ç”¨ NatureCode çš„å„ç§åŠŸèƒ½
 â€¢ è§£å†³ç¼–ç¨‹é—®é¢˜
 â€¢ ç®¡ç†é¡¹ç›®å’Œä»£ç 
 â€¢ æä¾› AI é©±åŠ¨çš„å¼€å‘å»ºè®®

 ğŸš€ æˆ‘èƒ½åšä»€ä¹ˆï¼š
 1. å›ç­” NatureCode ä½¿ç”¨é—®é¢˜
 2. æä¾›ä»£ç åˆ†æå’Œå®¡æŸ¥
 3. å¸®åŠ©é…ç½® AI æ¨¡å‹
 4. æŒ‡å¯¼ Git æ“ä½œ
 5. ååŠ©é¡¹ç›®ç®¡ç†

 ğŸ’¡ å¦‚ä½•ä¸æˆ‘äº’åŠ¨ï¼š
 â€¢ ç›´æ¥æé—®ï¼šnaturecode help "ä½ çš„é—®é¢˜"
 â€¢ å¯åŠ¨å¯¹è¯ï¼šnaturecode help
 â€¢ æŸ¥çœ‹å‘½ä»¤ï¼šnaturecode --help

 ğŸ“š äº†è§£æ›´å¤šï¼š
 â€¢ å®Œæ•´æ–‡æ¡£ï¼šnaturecode help --docs
 â€¢ ç®€å•å¸®åŠ©ï¼šnaturecode help --simple
 â€¢ å®‰è£… AIï¼šnaturecode help --install-ollama
`);
      } else if (
        lowerQuestion.includes("å¦‚ä½•å¼€å§‹") ||
        lowerQuestion.includes("how to start") ||
        lowerQuestion.includes("getting started")
      ) {
        console.log(`
 ğŸš€ å¦‚ä½•å¼€å§‹ä½¿ç”¨ NatureCodeï¼š

 1. é…ç½® AI æ¨¡å‹ï¼š
    naturecode model

 2. å¯åŠ¨äº¤äº’ä¼šè¯ï¼š
    naturecode start

 3. è·å–å¸®åŠ©ï¼š
    naturecode help "ä½ çš„é—®é¢˜"

 4. æŸ¥çœ‹æ‰€æœ‰å‘½ä»¤ï¼š
    naturecode --help

 ğŸ“¦ è‡ªåŠ¨å®‰è£… AI åŠ©æ‰‹ï¼š
 é¦–æ¬¡è¿è¡Œ naturecode help æ—¶ï¼Œä¼šè‡ªåŠ¨å®‰è£… Ollama å’Œ DeepSeek æ¨¡å‹ã€‚

 ğŸ”§ æ‰‹åŠ¨å®‰è£… AIï¼š
 - Ollama: curl -fsSL https://ollama.ai/install.sh | sh
 - DeepSeek æ¨¡å‹: ollama pull deepseek-coder

 ğŸ’¡ ç¤ºä¾‹ï¼š
    naturecode help "å¦‚ä½•é…ç½® DeepSeek API"
    naturecode help "æ€ä¹ˆä½¿ç”¨ Git åŠŸèƒ½"
    naturecode help "ä»£ç åˆ†ææ€ä¹ˆç”¨"
`);
      } else if (
        lowerQuestion.includes("é…ç½®") ||
        lowerQuestion.includes("configure") ||
        lowerQuestion.includes("model")
      ) {
        console.log(`
 ğŸ¤– é…ç½® AI æ¨¡å‹ï¼š

 NatureCode æ”¯æŒä¸‰ç§ AI æä¾›å•†ï¼š

 1. DeepSeek (æ¨è)
    - éœ€è¦ API å¯†é’¥ï¼šhttps://platform.deepseek.com/
    - è¿è¡Œï¼šnaturecode model
    - é€‰æ‹© DeepSeekï¼Œè¾“å…¥ API å¯†é’¥

 2. OpenAI
    - éœ€è¦ API å¯†é’¥ï¼šhttps://platform.openai.com/
    - è¿è¡Œï¼šnaturecode model
    - é€‰æ‹© OpenAIï¼Œè¾“å…¥ API å¯†é’¥

 3. Ollama (æœ¬åœ°ï¼Œå…è´¹)
    - è‡ªåŠ¨å®‰è£…ï¼šè¿è¡Œ naturecode help æ—¶è‡ªåŠ¨å®‰è£…
    - æˆ–æ‰‹åŠ¨ï¼šcurl -fsSL https://ollama.ai/install.sh | sh
    - æ¨¡å‹ï¼šollama pull deepseek-coder

 ğŸ“ é…ç½®æ–‡ä»¶ä½ç½®ï¼š~/.naturecode/config.json
`);
      } else if (
        lowerQuestion.includes("git") ||
        lowerQuestion.includes("ç‰ˆæœ¬æ§åˆ¶")
      ) {
        console.log(`
 ğŸ”§ Git é›†æˆåŠŸèƒ½ï¼š

 å¯ç”¨å‘½ä»¤ï¼š
   naturecode git status      # æŸ¥çœ‹ Git çŠ¶æ€
   naturecode git diff        # æŸ¥çœ‹æ›´æ”¹
   naturecode git commit      # æäº¤æ›´æ”¹
   naturecode git push        # æ¨é€åˆ°è¿œç¨‹ä»“åº“
   naturecode git pull        # ä»è¿œç¨‹æ‹‰å–

 ğŸ’¡ ç¤ºä¾‹ï¼š
   naturecode git status
   naturecode git commit -m "ä¿®å¤äº†bug"
   naturecode git push origin main
`);
      } else if (
        lowerQuestion.includes("ä»£ç ") ||
        lowerQuestion.includes("code") ||
        lowerQuestion.includes("åˆ†æ")
      ) {
        console.log(`
 ğŸ“Š ä»£ç åˆ†æåŠŸèƒ½ï¼š

 å¯ç”¨å‘½ä»¤ï¼š
   naturecode code analyze    # åˆ†æä»£ç è´¨é‡
   naturecode code review     # AI ä»£ç å®¡æŸ¥
   naturecode code metrics    # æ˜¾ç¤ºä»£ç æŒ‡æ ‡

 ğŸ’¡ ç¤ºä¾‹ï¼š
   naturecode code analyze src/
   naturecode code review main.js
   naturecode code metrics .
`);
      } else if (
        lowerQuestion.includes("å‘½ä»¤") ||
        lowerQuestion.includes("commands") ||
        lowerQuestion.includes("åŠŸèƒ½")
      ) {
        console.log(`
 ğŸ“‹ NatureCode ä¸»è¦åŠŸèƒ½ï¼š

 ğŸ¯ æ ¸å¿ƒåŠŸèƒ½ï¼š
 â€¢ AI åŠ©æ‰‹ï¼šnaturecode help
 â€¢ äº¤äº’ä¼šè¯ï¼šnaturecode start
 â€¢ æ¨¡å‹é…ç½®ï¼šnaturecode model

 ğŸ“ æ–‡ä»¶æ“ä½œï¼š
 â€¢ è¯»å–æ–‡ä»¶ï¼šnaturecode read <file>
 â€¢ ç¼–è¾‘æ–‡ä»¶ï¼šnaturecode edit <file>
 â€¢ åˆ›å»ºæ–‡ä»¶ï¼šnaturecode create <file>
 â€¢ åˆ é™¤æ–‡ä»¶ï¼šnaturecode delete <file>
 â€¢ åˆ—å‡ºç›®å½•ï¼šnaturecode list <dir>

 ğŸ”§ Git æ“ä½œï¼š
 â€¢ çŠ¶æ€æŸ¥çœ‹ï¼šnaturecode git status
 â€¢ å·®å¼‚å¯¹æ¯”ï¼šnaturecode git diff
 â€¢ æäº¤æ›´æ”¹ï¼šnaturecode git commit
 â€¢ æ¨é€ä»£ç ï¼šnaturecode git push
 â€¢ æ‹‰å–æ›´æ–°ï¼šnaturecode git pull

 ğŸ“Š ä»£ç åˆ†æï¼š
 â€¢ è´¨é‡åˆ†æï¼šnaturecode code analyze
 â€¢ AI å®¡æŸ¥ï¼šnaturecode code review
 â€¢ æŒ‡æ ‡ç»Ÿè®¡ï¼šnaturecode code metrics

 ğŸ—ï¸ é¡¹ç›®ç®¡ç†ï¼š
 â€¢ é¡¹ç›®åˆ†æï¼šnaturecode project analyze
 â€¢ åˆ›å»ºé¡¹ç›®ï¼šnaturecode project create
 â€¢ ä¾èµ–åˆ†æï¼šnaturecode project deps

 ğŸ”Œ æ’ä»¶ç³»ç»Ÿï¼š
 â€¢ æ’ä»¶åˆ—è¡¨ï¼šnaturecode plugin list
 â€¢ æ’ä»¶ä¿¡æ¯ï¼šnaturecode plugin info <id>
 â€¢ å®‰è£…æ’ä»¶ï¼šnaturecode plugin install <source>

 ğŸ’¡ æ›´å¤šå¸®åŠ©ï¼š
 â€¢ æŸ¥çœ‹æ‰€æœ‰å‘½ä»¤ï¼šnaturecode --help
 â€¢ å®Œæ•´æ–‡æ¡£ï¼šnaturecode help --docs
 â€¢ AI å¯¹è¯ï¼šnaturecode help
`);
      } else if (
        lowerQuestion.includes("hello") ||
        lowerQuestion.includes("hi") ||
        lowerQuestion.includes("ä½ å¥½")
      ) {
        console.log(`
 ğŸ‘‹ ä½ å¥½ï¼æˆ‘æ˜¯ NatureCode AI åŠ©æ‰‹ï¼

 å¾ˆé«˜å…´è§åˆ°ä½ ï¼æˆ‘æ˜¯ NatureCode v1.4.5.5 çš„æ™ºèƒ½åŠ©æ‰‹ã€‚

 ğŸš€ æˆ‘èƒ½å¸®åŠ©ä½ ï¼š
 â€¢ å›ç­” NatureCode ä½¿ç”¨é—®é¢˜
 â€¢ æä¾›ç¼–ç¨‹å¸®åŠ©å’Œä»£ç åˆ†æ
 â€¢ ç®¡ç†æ–‡ä»¶å’Œé¡¹ç›®
 â€¢ é…ç½® AI æ¨¡å‹å’Œå·¥å…·

 ğŸ’¡ è¯•è¯•è¿™äº›å‘½ä»¤ï¼š
   naturecode start          # å¯åŠ¨äº¤äº’ä¼šè¯
   naturecode help "å¦‚ä½•å¼€å§‹" # è·å–å…¥é—¨æŒ‡å—
   naturecode model          # é…ç½® AI æ¨¡å‹
   naturecode --help         # æŸ¥çœ‹æ‰€æœ‰å‘½ä»¤

 ğŸ“š äº†è§£æ›´å¤šï¼š
 â€¢ å®Œæ•´æ–‡æ¡£ï¼šnaturecode help --docs
 â€¢ AI å¸®åŠ©ï¼šnaturecode help (éœ€è¦ Ollama)
 â€¢ ç®€å•å¸®åŠ©ï¼šnaturecode help --simple

 ğŸ¤– AI åŠ©æ‰‹çŠ¶æ€ï¼š
 ç³»ç»Ÿæ£€æµ‹åˆ° Ollama å·²å®‰è£…ï¼Œä½† AI æ¨¡å‹å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´åŠ è½½ã€‚
 é¦–æ¬¡ä½¿ç”¨æˆ–é•¿æ—¶é—´æœªä½¿ç”¨åï¼Œæ¨¡å‹åŠ è½½å¯èƒ½éœ€è¦ 1-2 åˆ†é’Ÿã€‚
`);
      } else {
        // General help from docs
        const introMatch = docsContext.match(/(^.*?##.*?\n)/s);
        if (introMatch) {
          console.log(introMatch[1]);
        }

        console.log(`
 ğŸ” æ ¹æ®æ‚¨çš„é—®é¢˜ "${question}"ï¼Œå»ºè®®ï¼š

 1. æŸ¥çœ‹å®Œæ•´æ–‡æ¡£ï¼šè¿è¡Œ naturecode help --docs
 2. è·å– AI å¸®åŠ©ï¼ˆéœ€è¦å®‰è£… Ollamaï¼‰ï¼š
    - è‡ªåŠ¨å®‰è£…ï¼šè¿è¡Œ naturecode help
    - æ‰‹åŠ¨å®‰è£…ï¼šcurl -fsSL https://ollama.ai/install.sh | sh
 3. æŸ¥çœ‹ç®€å•å¸®åŠ©ï¼šnaturecode help --simple

 ğŸ’¡ å¸¸è§é—®é¢˜ï¼š
   â€¢ ä½ æ˜¯è°ï¼Ÿ â†’ naturecode help "ä½ æ˜¯è°"
   â€¢ å¦‚ä½•å¼€å§‹ï¼Ÿ â†’ naturecode help "å¦‚ä½•å¼€å§‹"
   â€¢ æ€ä¹ˆé…ç½® AIï¼Ÿ â†’ naturecode help "é…ç½® AI"
   â€¢ Git æ€ä¹ˆç”¨ï¼Ÿ â†’ naturecode help "Git åŠŸèƒ½"
   â€¢ ä»£ç åˆ†æï¼Ÿ â†’ naturecode help "ä»£ç åˆ†æ"
   â€¢ æœ‰å“ªäº›å‘½ä»¤ï¼Ÿ â†’ naturecode help "å‘½ä»¤"
   â€¢ Hello/ä½ å¥½ â†’ naturecode help "hello"
`);
      }

      console.log("=".repeat(70));
      console.log("\néœ€è¦å®Œæ•´ AI å¸®åŠ©ï¼Ÿè¿è¡Œ: naturecode help");
      console.log("ï¼ˆé¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨å®‰è£… Ollama å’Œ AI æ¨¡å‹ï¼‰");
    } catch (error) {
      console.log("\næ˜¾ç¤ºç®€å•å¸®åŠ©...");
      await this.showSimpleHelp();
    }
  }
}

// Export for testing
export default HelpCommand;
